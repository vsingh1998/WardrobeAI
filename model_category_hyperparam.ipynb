{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 10:04:23.330799: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-07-19 10:04:23.330824: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import remove_items, split_data, group_color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_df(csv_path=\"data/styles.csv\"):\n",
    "      \"\"\"\n",
    "      function to fetch and clean the data\n",
    "\n",
    "      input : csv_path, path to .csv file\n",
    "      return: styles, dataframe\n",
    "      \"\"\"\n",
    "\n",
    "      styles = pd.read_csv(csv_path, on_bad_lines='skip')\n",
    "\n",
    "      # drop unnecessary columns which are not needed to make recommendation\n",
    "      styles = styles.drop([\"productDisplayName\"], axis=1) \n",
    "      styles = styles.drop([\"year\"], axis=1) \n",
    "      styles = styles[(styles.masterCategory=='Apparel')|(styles.masterCategory=='Footwear')]\n",
    "      styles = styles.drop(styles[styles[\"subCategory\"]==\"Innerwear\"].index)\n",
    "      styles = styles.dropna()\n",
    "\n",
    "      styles = remove_items(styles,\"subCategory\", [\"Apparel Set\", \"Dress\", \"Loungewear and Nightwear\", \"Saree\", \"Socks\"])\n",
    "      styles[\"subCategory\"] = styles[\"subCategory\"].transform(lambda x: \"Footwear\" if (x in [\"Shoes\", \"Flip Flops\", \"Sandal\"]) else x)\n",
    "      styles = styles.drop(labels = [6695, 16194, 32309, 36381, 40000], axis=0) # drop incomplete rows\n",
    "\n",
    "      # group colors to the color-wheel\n",
    "      group_color(styles) \n",
    "\n",
    "      return styles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Topwear', 'Bottomwear', 'Footwear'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "styles = clean_df()\n",
    "styles[\"subCategory\"].unique() # sanity check after cleaning df: three subcategories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "styles[\"subCategory\"] = le.fit_transform(styles[\"subCategory\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_array(df):\n",
    "      \"\"\"\n",
    "      function to fetch dataset \n",
    "\n",
    "      input : dataframe\n",
    "      return: dataset\n",
    "      \"\"\"\n",
    "\n",
    "      train_imgs = np.zeros((len(df.id), 80, 60, 3))\n",
    "\n",
    "      for i in range(len(df.id)):      \n",
    "        ID = df.id.iloc[i]\n",
    "        img_path = f\"data/images/{ID}.jpg\"   \n",
    "        img = cv2.imread(img_path)\n",
    "\n",
    "        if img.shape != (80, 60, 3):\n",
    "          img = image.load_img(img_path, target_size=(80, 60, 3))\n",
    "\n",
    "        train_imgs[i] = img\n",
    "\n",
    "      data = tf.data.Dataset.from_tensor_slices(\n",
    "      (\n",
    "        {\n",
    "          \"images\": train_imgs\n",
    "        },\n",
    "        \n",
    "        {\n",
    "          \"subCategory\": df[[\"subCategory\"]]\n",
    "        }\n",
    "      )\n",
    "      )\n",
    "\n",
    "      return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(width, height, num_classes, hparam):\n",
    "        \"\"\"\n",
    "        function to build model for subCategories\n",
    "\n",
    "        input : width, image width \n",
    "                height, image height\n",
    "                num_classes, number of classes\n",
    "        return: keras.Model\n",
    "        \"\"\"\n",
    "\n",
    "        resnet50 = keras.applications.ResNet50(weights='imagenet', include_top=False, input_shape=(80, 60, 3))\n",
    "        resnet50.trainable=False\n",
    "\n",
    "        inputs = keras.Input(shape=(width,height,3), name=\"images\")\n",
    "\n",
    "        x = layers.RandomFlip(\"horizontal\")(inputs)\n",
    "        x = layers.RandomRotation(factor=0.2)(x)\n",
    "        x = layers.RandomZoom(height_factor=0.1, width_factor=0.1)(x)\n",
    "        x = layers.RandomContrast(factor=0.2)(x)\n",
    "\n",
    "        x = resnet50(x, training=False)\n",
    "        x = layers.Conv2D(32, (2, 2), activation='relu')(x)\n",
    "        x = layers.Flatten()(x)\n",
    "        x = layers.Dense(1024, activation='relu', kernel_regularizer=keras.regularizers.l2(l=hparam[3]))(x)\n",
    "        x = layers.Dense(512, activation=\"relu\", kernel_regularizer=keras.regularizers.l2(l=hparam[3]))(x)\n",
    "        x = layers.Dropout(hparam[1])(x)\n",
    "        x = layers.Dense(256, activation='relu', kernel_regularizer=keras.regularizers.l2(l=hparam[3]))(x)\n",
    "        x = layers.Dropout(hparam[1])(x)\n",
    "        x = layers.Dense(128, activation='relu', kernel_regularizer=keras.regularizers.l2(l=hparam[3]))(x)\n",
    "        x = layers.Dropout(hparam[1])(x)\n",
    "        x = layers.Dense(64, activation='relu', kernel_regularizer=keras.regularizers.l2(l=hparam[3]))(x)\n",
    "        x = layers.Dropout(hparam[1])(x)\n",
    "        x = layers.Dense(len(num_classes))(x)\n",
    "        x = layers.Activation('softmax', name='subCategory')(x)\n",
    "\n",
    "        model = keras.Model(inputs=inputs, outputs=x)\n",
    "\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 10:04:42.546702: E tensorflow/stream_executor/cuda/cuda_driver.cc:271] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2022-07-19 10:04:42.546786: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (vikram-HP-Pavilion-Laptop-14-bf1xx): /proc/driver/nvidia/version does not exist\n",
      "2022-07-19 10:04:42.547665: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-07-19 10:04:42.550495: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3140928000 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "sub_train, sub_val, sub_test = split_data(create_array(styles), batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs_list = [5, 10, 15]\n",
    "dropout_list = [0.1, 0.25]\n",
    "learning_rates = [1e-3, 1e-4]\n",
    "regularization_list = [0.1, 0.25]\n",
    "\n",
    "# function to get hyperparameter combinations\n",
    "def get_hyperparameter_combinations(epochs, dropout, learning_rates, reg):\n",
    "  hyperparameters_list = [epochs, dropout, learning_rates, reg]\n",
    "  hyperparameters_comb = list(itertools.product(*hyperparameters_list))\n",
    "  return hyperparameters_comb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperparameter_tuning(hyperparameters_comb):\n",
    "        best_acc = 0\n",
    "        for i, hparam in enumerate(hyperparameters_comb):\n",
    "                print('\\nCOMBO', i, hparam)\n",
    "                test_net = build_model(80, 60, num_classes=le.classes_, hparam=hparam)\n",
    "                test_net.compile(optimizer='adam',\n",
    "                                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "                                metrics=['accuracy'])\n",
    "                with tf.device(\"/gpu:0\"):\n",
    "                        test_stats = test_net.fit(sub_train, epochs=hparam[0], validation_data=sub_val)\n",
    "\n",
    "                score = test_net.evaluate(sub_test)\n",
    "                current_acc = score[1]\n",
    "                print('Current accuracy for', i, 'th combination is:', current_acc)\n",
    "\n",
    "                if current_acc > best_acc:\n",
    "                        best_acc = current_acc\n",
    "                        best_idx = i\n",
    "                        best_net = test_net\n",
    "                        best_stats = test_stats\n",
    "        return best_idx, best_stats, best_net, best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "COMBO 0 (5, 0.1, 0.001, 0.001)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 10:04:52.815676: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3140928000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "511/511 [==============================] - ETA: 0s - loss: 0.5974 - accuracy: 0.9572"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 10:07:19.094979: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3140928000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "511/511 [==============================] - 204s 384ms/step - loss: 0.5974 - accuracy: 0.9572 - val_loss: 0.1971 - val_accuracy: 0.9906\n",
      "Epoch 2/5\n",
      "511/511 [==============================] - 197s 386ms/step - loss: 0.1561 - accuracy: 0.9838 - val_loss: 0.1132 - val_accuracy: 0.9860\n",
      "Epoch 3/5\n",
      "511/511 [==============================] - 200s 392ms/step - loss: 0.1007 - accuracy: 0.9850 - val_loss: 0.0656 - val_accuracy: 0.9903\n",
      "Epoch 4/5\n",
      "511/511 [==============================] - 193s 377ms/step - loss: 0.0755 - accuracy: 0.9865 - val_loss: 0.0494 - val_accuracy: 0.9908\n",
      "Epoch 5/5\n",
      "511/511 [==============================] - 192s 375ms/step - loss: 0.0592 - accuracy: 0.9885 - val_loss: 0.0617 - val_accuracy: 0.9871\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-19 10:21:21.662466: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 3140928000 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170/170 [==============================] - 54s 266ms/step - loss: 0.0592 - accuracy: 0.9879\n",
      "Current accuracy for 0 th combination is: 0.9878676533699036\n",
      "\n",
      "COMBO 1 (5, 0.1, 0.001, 0.1)\n",
      "Epoch 1/5\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "WARNING:tensorflow:Using a while_loop for converting RngReadAndSkip\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting Bitcast\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformFullIntV2\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomGetKeyCounter\n",
      "WARNING:tensorflow:Using a while_loop for converting StatelessRandomUniformV2\n",
      "WARNING:tensorflow:Using a while_loop for converting AdjustContrastv2\n",
      "511/511 [==============================] - 201s 379ms/step - loss: 7.2289 - accuracy: 0.9264 - val_loss: 0.3169 - val_accuracy: 0.9757\n",
      "Epoch 2/5\n",
      "146/511 [=======>......................] - ETA: 1:50 - loss: 0.3177 - accuracy: 0.9692"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21281/1415579780.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mhyperparameters_comb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_hyperparameter_combinations\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepochs_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdropout_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mregularization_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mbest_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_stats\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbest_net\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhyperparameter_tuning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhyperparameters_comb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Best Validation score : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_acc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Hidden size used : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters_comb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'No of iterations required : '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhyperparameters_comb\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbest_idx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_21281/2601862175.py\u001b[0m in \u001b[0;36mhyperparameter_tuning\u001b[0;34m(hyperparameters_comb)\u001b[0m\n\u001b[1;32m      8\u001b[0m                                 metrics=['accuracy'])\n\u001b[1;32m      9\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/gpu:0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m                         \u001b[0mtest_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparam\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msub_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                 \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msub_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1407\u001b[0m                 _r=1):\n\u001b[1;32m   1408\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1409\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1410\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1411\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    913\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 915\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    917\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    945\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2451\u001b[0m       (graph_function,\n\u001b[1;32m   2452\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   2454\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   2455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1858\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1859\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1860\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1861\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1862\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    496\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    498\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hyperparameters_comb = get_hyperparameter_combinations(epochs_list, dropout_list, learning_rates, regularization_list)\n",
    "best_idx, best_stats, best_net, best_acc = hyperparameter_tuning(hyperparameters_comb)\n",
    "print('Best Test score : ', best_acc)\n",
    "print('Hidden size used : ', hyperparameters_comb[best_idx][1])\n",
    "print('No of iterations required : ', hyperparameters_comb[best_idx][0])\n",
    "print('Learning rate used : ', hyperparameters_comb[best_idx][2])\n",
    "print('regularization strength : ', hyperparameters_comb[best_idx][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_net.evaluate(sub_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size = 32\n",
    "# epochs = 15\n",
    "\n",
    "# sub_train, sub_val, sub_test = split_data(create_array(styles), batch_size=batch_size)\n",
    "\n",
    "# sub_model = build_model(80, 60, num_classes=le.classes_)\n",
    "# sub_model.summary()\n",
    "\n",
    "# sub_model.compile(optimizer='adam',\n",
    "#                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False),\n",
    "#                   metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_model(sub_model, to_file='model_category.png')\n",
    "\n",
    "# with tf.device(\"/gpu:0\"):\n",
    "#     best_stats = sub_model.fit(sub_train, epochs=epochs, validation_data=sub_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best_stats.history['loss'], label='train_loss')\n",
    "plt.plot(best_stats.history['val_loss'], label='val_loss')\n",
    "plt.title(\"Loss Curve\")\n",
    "plt.xlabel(\"Epochs\"), plt.ylabel(\"Loss\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(best_stats.history['accuracy'], label='train_accuracy')\n",
    "plt.plot(best_stats.history['val_accuracy'], label='val_accuracy')\n",
    "plt.title(\"Accuracy Curve\")\n",
    "plt.xlabel(\"Epoch\"), plt.ylabel(\"Accuracy\"), plt.legend(loc=\"best\")\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sub_model.evaluate(sub_test)\n",
    "# sub_model.save(\"/models/models/model_category\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
